{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Tokenization with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens():\n",
    "    with open('./article/art1.dat','r') as article:\n",
    "        text = article.read()\n",
    "        lowers = text.lower()\n",
    "        no_punctuation = lowers.translate(string.punctuation)\n",
    "        tokens = nltk.word_tokenize(no_punctuation)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Counter.most_common of Counter({'the': 9, ',': 6, 'to': 4, 'a': 4, 'ringgit': 3, 'in': 3, 'on': 3, '.': 3, '%': 3, 'us': 2, 'death-cross': 2, 'pattern': 2, 'has': 2, 'this': 2, 'previous': 2, 'took': 2, 'dollar': 2, 'of': 2, '3': 2, 'from': 2, 'trading': 2, 'strengthen': 1, 'against': 1, 'dollar.+the': 1, 'dollar-ringgit': 1, 'exchange': 1, 'rate': 1, 'is': 1, 'forming': 1, 'which': 1, 'past': 1, 'led': 1, 'decline': 1, 'currency': 1, 'pair': 1, 'based': 1, 'technical': 1, 'charts': 1, '+bloomberg': 1, 'reported': 1, 'wednesday': 1, 'that': 1, 'occurs': 1, 'when': 1, '50-day': 1, 'moving': 1, 'average': 1, 'drops': 1, 'below': 1, '100-day': 1, 'gauge': 1, '+it': 1, 'said': 1, 'three': 1, 'occasions': 1, 'move': 1, 'place': 1, 'posted': 1, 'additional': 1, 'losses': 1, 'and': 1, '7': 1, 'before': 1, 'finding': 1, 'bottom': 1, '+the': 1, 'underperformed': 1, 'asian': 1, 'currencies': 1, 'since': 1, 'policy': 1, 'makers': 1, 'steps': 1, 'november': 1, 'deter': 1, 'foreign': 1, 'banks': 1, 'non-deliverable': 1, 'forwards': 1, 'wire': 1, 'report': 1, 'said.+at': 1, '1.45pm': 1, 'was': 1, 'at': 1, '4.4305': 1, 'close': 1, '4.4312.+': 1})>\n"
     ]
    }
   ],
   "source": [
    "tokens = get_tokens()\n",
    "count = Counter(tokens)\n",
    "print(count.most_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Stop words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 6), ('ringgit', 3), ('.', 3), ('%', 3), ('us', 2), ('death-cross', 2), ('pattern', 2), ('previous', 2), ('took', 2), ('dollar', 2), ('3', 2), ('trading', 2), ('strengthen', 1), ('dollar.+the', 1), ('dollar-ringgit', 1), ('exchange', 1), ('rate', 1), ('forming', 1), ('past', 1), ('led', 1), ('decline', 1), ('currency', 1), ('pair', 1), ('based', 1), ('technical', 1), ('charts', 1), ('+bloomberg', 1), ('reported', 1), ('wednesday', 1), ('occurs', 1), ('50-day', 1), ('moving', 1), ('average', 1), ('drops', 1), ('100-day', 1), ('gauge', 1), ('+it', 1), ('said', 1), ('three', 1), ('occasions', 1), ('move', 1), ('place', 1), ('posted', 1), ('additional', 1), ('losses', 1), ('7', 1), ('finding', 1), ('bottom', 1), ('+the', 1), ('underperformed', 1), ('asian', 1), ('currencies', 1), ('since', 1), ('policy', 1), ('makers', 1), ('steps', 1), ('november', 1), ('deter', 1), ('foreign', 1), ('banks', 1), ('non-deliverable', 1), ('forwards', 1), ('wire', 1), ('report', 1), ('said.+at', 1), ('1.45pm', 1), ('4.4305', 1), ('close', 1), ('4.4312.+', 1)]\n"
     ]
    }
   ],
   "source": [
    "tokens = get_tokens()\n",
    "filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
    "count = Counter(filtered)\n",
    "print(count.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Stemming with Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 6), ('ringgit', 3), ('.', 3), ('%', 3), ('us', 2), ('death-cross', 2), ('pattern', 2), ('currenc', 2), ('report', 2), ('move', 2), ('previou', 2), ('took', 2), ('dollar', 2), ('3', 2), ('trade', 2), ('strengthen', 1), ('dollar.+th', 1), ('dollar-ringgit', 1), ('exchang', 1), ('rate', 1), ('form', 1), ('past', 1), ('led', 1), ('declin', 1), ('pair', 1), ('base', 1), ('technic', 1), ('chart', 1), ('+bloomberg', 1), ('wednesday', 1), ('occur', 1), ('50-day', 1), ('averag', 1), ('drop', 1), ('100-day', 1), ('gaug', 1), ('+it', 1), ('said', 1), ('three', 1), ('occas', 1), ('place', 1), ('post', 1), ('addit', 1), ('loss', 1), ('7', 1), ('find', 1), ('bottom', 1), ('+the', 1), ('underperform', 1), ('asian', 1), ('sinc', 1), ('polici', 1), ('maker', 1), ('step', 1), ('novemb', 1), ('deter', 1), ('foreign', 1), ('bank', 1), ('non-deliver', 1), ('forward', 1), ('wire', 1), ('said.+at', 1), ('1.45pm', 1), ('4.4305', 1), ('close', 1), ('4.4312.+', 1)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stemmed = stem_tokens(filtered, stemmer)\n",
    "count = Counter(stemmed)\n",
    "print(count.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: tf-idf with Scikit-learn (combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "from collections import Counter\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from collections import defaultdict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/muhdlaziem/Workspace/NLP/Week8/article'\n",
    "token_dict ={}\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/muhdlaziem/Workspace/NLP/Week8/article/art1.dat\n",
      "/home/muhdlaziem/Workspace/NLP/Week8/article/art3.dat\n",
      "/home/muhdlaziem/Workspace/NLP/Week8/article/art4.dat\n",
      "/home/muhdlaziem/Workspace/NLP/Week8/article/art2.dat\n",
      "/home/muhdlaziem/Workspace/NLP/Week8/article/art6.dat\n",
      "/home/muhdlaziem/Workspace/NLP/Week8/article/art5.dat\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems  = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "for subdir, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        file_path =  subdir + os.path.sep + file\n",
    "        print(file_path)\n",
    "        article = open(file_path,'r')\n",
    "        text = article.read()\n",
    "        lowers = text.lower()\n",
    "        no_punctuation = lowers.translate(string.punctuation)\n",
    "        token_dict[file] = no_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words=['english'])\n",
    "tfs = tfidf.fit_transform((token_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            art1.dat  art3.dat  art4.dat  art2.dat  art6.dat  art5.dat\n",
      "$           0.000000  0.000000       0.0  0.241775  0.000000  0.000000\n",
      "%           0.242364  0.000000       0.0  0.000000  0.000000  0.000000\n",
      "''          0.000000  0.000000       0.0  0.000000  0.053996  0.107424\n",
      "'s          0.000000  0.173227       0.0  0.055795  0.000000  0.136042\n",
      "+bloomberg  0.080788  0.000000       0.0  0.000000  0.000000  0.000000\n",
      "...              ...       ...       ...       ...       ...       ...\n",
      "year        0.000000  0.000000       0.0  0.161183  0.000000  0.000000\n",
      "yen         0.000000  0.062554       0.0  0.000000  0.000000  0.000000\n",
      "ying        0.000000  0.062554       0.0  0.000000  0.000000  0.000000\n",
      "yoo         0.000000  0.062554       0.0  0.000000  0.000000  0.000000\n",
      "you         0.000000  0.000000       0.0  0.000000  0.000000  0.131003\n",
      "\n",
      "[511 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf.get_feature_names()\n",
    "corpus_index = [n for n in token_dict]\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(tfs.T.todense(), index=feature_names, columns=corpus_index)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game\n",
      "\n",
      "art1.dat    0.000000\n",
      "art3.dat    0.102590\n",
      "art4.dat    0.131752\n",
      "art2.dat    0.000000\n",
      "art6.dat    0.000000\n",
      "art5.dat    0.000000\n",
      "Name: game, dtype: float64\n",
      "\n",
      "\n",
      "ringgit\n",
      "\n",
      "art1.dat    0.242364\n",
      "art3.dat    0.000000\n",
      "art4.dat    0.000000\n",
      "art2.dat    0.000000\n",
      "art6.dat    0.000000\n",
      "art5.dat    0.000000\n",
      "Name: ringgit, dtype: float64\n",
      "\n",
      "\n",
      "trade\n",
      "\n",
      "art1.dat    0.132495\n",
      "art3.dat    0.000000\n",
      "art4.dat    0.000000\n",
      "art2.dat    0.264345\n",
      "art6.dat    0.000000\n",
      "art5.dat    0.000000\n",
      "Name: trade, dtype: float64\n",
      "\n",
      "\n",
      "win\n",
      "\n",
      "art1.dat    0.000000\n",
      "art3.dat    0.043307\n",
      "art4.dat    0.055617\n",
      "art2.dat    0.000000\n",
      "art6.dat    0.000000\n",
      "art5.dat    0.045347\n",
      "Name: win, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr = pd.DataFrame()\n",
    "strings = ['win','ringgit','trade','game','killed']\n",
    "for i in df.index:\n",
    "    if i in strings:\n",
    "        print(i +'\\n')\n",
    "        print(df.loc[i])\n",
    "#         arr.append(df.loc[i])\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "art1.dat    0.242364\n",
       "art3.dat    0.000000\n",
       "art4.dat    0.000000\n",
       "art2.dat    0.000000\n",
       "art6.dat    0.000000\n",
       "art5.dat    0.000000\n",
       "Name: %, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i in df:\n",
    "    print(i)\n",
    "    if i in strings:\n",
    "        print(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster: \n",
      "Cluster 0: \n",
      " the\n",
      " ,\n",
      " to\n",
      " a\n",
      " of\n",
      " on\n",
      " and\n",
      " .\n",
      " wa\n",
      " in\n",
      "Cluster 1: \n",
      " trade\n",
      " $\n",
      " deficit\n",
      " high\n",
      " billion\n",
      " year\n",
      " export\n",
      " near\n",
      " two-year\n",
      " china\n"
     ]
    }
   ],
   "source": [
    "def k_means(tfs):\n",
    "    true_k=2\n",
    "    model = KMeans(n_clusters=true_k, init='k-means++', max_iter=50,n_init=1)\n",
    "    model.fit(tfs)\n",
    "    print(\"Top terms per cluster: \")\n",
    "    order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "    terms = tfidf.get_feature_names()\n",
    "    \n",
    "    for i in range(true_k):\n",
    "        print(\"Cluster %d: \" % i)\n",
    "        for ind in order_centroids[i, :10]:\n",
    "#             print(ind)\n",
    "            print(' %s' % terms[ind])\n",
    "k_means(tfs)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['win', 'ringgit', 'trade', 'game', 'killed']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$',\n",
       " '%',\n",
       " \"''\",\n",
       " \"'s\",\n",
       " '+bloomberg',\n",
       " '+it',\n",
       " '+the',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '1',\n",
       " '1-1',\n",
       " '1.45pm',\n",
       " '100-day',\n",
       " '15',\n",
       " '2-0',\n",
       " '20',\n",
       " '2013',\n",
       " '2016',\n",
       " '21',\n",
       " '21-13',\n",
       " '21-16',\n",
       " '21-17',\n",
       " '21-17.+the',\n",
       " '21-18',\n",
       " '21-19',\n",
       " '22-20',\n",
       " '22.+the',\n",
       " '23',\n",
       " '23-21',\n",
       " '26.6',\n",
       " '27th',\n",
       " '28-year-old',\n",
       " '3',\n",
       " '4.4305',\n",
       " '4.4312.+',\n",
       " '43.6',\n",
       " '44',\n",
       " '48.2',\n",
       " '5-3',\n",
       " '50-day',\n",
       " '52-year-old',\n",
       " '54',\n",
       " '6-21',\n",
       " '6-3',\n",
       " '6-4',\n",
       " '7',\n",
       " '75',\n",
       " '9.6',\n",
       " '94th-minut',\n",
       " ':',\n",
       " ';',\n",
       " '``',\n",
       " 'a',\n",
       " 'abbey',\n",
       " 'abov',\n",
       " 'across',\n",
       " 'ad',\n",
       " 'addit',\n",
       " 'administr',\n",
       " 'affect',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ahead',\n",
       " 'all',\n",
       " 'allow',\n",
       " 'also',\n",
       " 'although',\n",
       " 'alway',\n",
       " 'american',\n",
       " 'an',\n",
       " 'and',\n",
       " 'argentin',\n",
       " 'argentina',\n",
       " 'arsen',\n",
       " 'as',\n",
       " 'ashley',\n",
       " 'asian',\n",
       " 'assault',\n",
       " 'at',\n",
       " 'atmospher',\n",
       " 'attack',\n",
       " 'averag',\n",
       " 'aysha',\n",
       " 'bank',\n",
       " 'base',\n",
       " 'be',\n",
       " 'beat',\n",
       " 'befor',\n",
       " 'behind',\n",
       " 'below',\n",
       " 'between',\n",
       " 'billion',\n",
       " 'blow',\n",
       " 'boost',\n",
       " 'bottom',\n",
       " 'break',\n",
       " 'bridg',\n",
       " 'bridge.+',\n",
       " 'british',\n",
       " 'brother',\n",
       " 'but',\n",
       " 'by',\n",
       " 'camp',\n",
       " 'cancel',\n",
       " 'centr',\n",
       " 'chan',\n",
       " 'chant',\n",
       " 'chart',\n",
       " 'chin',\n",
       " 'china',\n",
       " 'choi',\n",
       " 'chun',\n",
       " 'chung-tang',\n",
       " 'citi',\n",
       " 'claudio',\n",
       " 'cleaner',\n",
       " 'close',\n",
       " 'club',\n",
       " 'cochran',\n",
       " 'commerc',\n",
       " 'commun',\n",
       " 'conced',\n",
       " 'continu',\n",
       " 'convert',\n",
       " 'could',\n",
       " 'court',\n",
       " 'court.+it',\n",
       " 'craig',\n",
       " 'crandon',\n",
       " 'crash',\n",
       " 'crowd',\n",
       " 'currenc',\n",
       " 'death',\n",
       " 'death-cross',\n",
       " 'declin',\n",
       " 'defeat',\n",
       " 'deficit',\n",
       " 'del',\n",
       " 'deliber',\n",
       " 'deliv',\n",
       " 'demand',\n",
       " 'depart',\n",
       " 'deter',\n",
       " 'differ',\n",
       " 'dismiss',\n",
       " 'dollar',\n",
       " 'dollar-ringgit',\n",
       " 'dollar.+th',\n",
       " 'domest',\n",
       " 'donald',\n",
       " 'doubl',\n",
       " 'doubles.+pang',\n",
       " 'down',\n",
       " 'dramat',\n",
       " 'draw',\n",
       " 'drawn',\n",
       " 'drop',\n",
       " 'drove',\n",
       " 'duo',\n",
       " 'dure',\n",
       " 'earli',\n",
       " 'earlier',\n",
       " 'earn',\n",
       " 'economist',\n",
       " 'edge.+',\n",
       " 'edi',\n",
       " 'emanuel',\n",
       " 'encount',\n",
       " 'end',\n",
       " 'enjoy',\n",
       " 'everton',\n",
       " 'exchang',\n",
       " 'exit',\n",
       " 'export',\n",
       " 'extend',\n",
       " 'factor',\n",
       " 'fail',\n",
       " 'fall',\n",
       " 'famili',\n",
       " 'favourit',\n",
       " 'februari',\n",
       " 'feder',\n",
       " 'fell',\n",
       " 'fifth',\n",
       " 'find',\n",
       " 'first',\n",
       " 'follow',\n",
       " 'football-styl',\n",
       " 'for',\n",
       " 'forc',\n",
       " 'forecourt.+lesli',\n",
       " 'forehand',\n",
       " 'foreign',\n",
       " 'form',\n",
       " 'former',\n",
       " 'former.+',\n",
       " 'forward',\n",
       " 'four',\n",
       " 'fourth',\n",
       " 'fourth-plac',\n",
       " 'frade',\n",
       " 'from',\n",
       " 'game',\n",
       " 'gap',\n",
       " 'gate',\n",
       " 'gaug',\n",
       " 'gave',\n",
       " 'global',\n",
       " 'goal',\n",
       " 'goh',\n",
       " 'goods.+th',\n",
       " 'got',\n",
       " 'growth',\n",
       " 'guard',\n",
       " 'ha',\n",
       " 'had',\n",
       " 'handbal',\n",
       " 'harri',\n",
       " 'have',\n",
       " 'he',\n",
       " 'held',\n",
       " 'hi',\n",
       " 'high',\n",
       " 'highest',\n",
       " 'himself',\n",
       " 'home',\n",
       " 'hong',\n",
       " 'hoo',\n",
       " 'hope',\n",
       " 'huat-shevon',\n",
       " 'i',\n",
       " 'ibrahimov',\n",
       " 'import',\n",
       " 'imports.+th',\n",
       " 'in',\n",
       " 'includ',\n",
       " 'increas',\n",
       " 'indonesian',\n",
       " 'injur',\n",
       " 'interest',\n",
       " 'into',\n",
       " 'is',\n",
       " 'islam',\n",
       " 'it',\n",
       " 'jagielka',\n",
       " 'januari',\n",
       " 'january.+',\n",
       " 'japan',\n",
       " 'jemi',\n",
       " 'jing',\n",
       " 'jinp',\n",
       " 'join',\n",
       " 'jose',\n",
       " 'juan',\n",
       " 'jung',\n",
       " 'just',\n",
       " 'kate',\n",
       " 'kazuno-ayan',\n",
       " 'keith',\n",
       " 'kenta',\n",
       " 'kian',\n",
       " 'kill',\n",
       " 'kiong',\n",
       " 'know',\n",
       " 'known',\n",
       " 'kong.+two',\n",
       " 'korea',\n",
       " 'kurihara.+n',\n",
       " 'kurt',\n",
       " 'lai',\n",
       " 'larg',\n",
       " 'last-gasp',\n",
       " 'later',\n",
       " 'lead',\n",
       " 'leagu',\n",
       " 'led',\n",
       " 'leicest',\n",
       " 'level',\n",
       " 'like',\n",
       " 'liu',\n",
       " 'london',\n",
       " 'lose',\n",
       " 'loss',\n",
       " 'lost',\n",
       " 'major',\n",
       " 'maker',\n",
       " 'malaysia',\n",
       " 'malaysian',\n",
       " 'man',\n",
       " 'manag',\n",
       " 'manchest',\n",
       " 'march',\n",
       " 'mark',\n",
       " 'martin',\n",
       " 'masood',\n",
       " 'match',\n",
       " 'matches.+but',\n",
       " 'meant',\n",
       " 'medallist',\n",
       " 'meet',\n",
       " 'memori',\n",
       " 'men',\n",
       " 'meng-lai',\n",
       " 'meng-pei',\n",
       " 'miami',\n",
       " 'mix',\n",
       " 'momentum',\n",
       " 'monday.+del',\n",
       " 'more',\n",
       " 'mourinho',\n",
       " 'move',\n",
       " 'myself',\n",
       " 'narrow',\n",
       " 'nation',\n",
       " 'near',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'non-deliver',\n",
       " 'novemb',\n",
       " 'now',\n",
       " 'occas',\n",
       " 'occur',\n",
       " 'of',\n",
       " 'off',\n",
       " 'offic',\n",
       " 'old',\n",
       " 'olymp',\n",
       " 'on',\n",
       " 'on.+zlatan',\n",
       " 'open',\n",
       " 'open+n',\n",
       " 'or',\n",
       " 'other',\n",
       " 'out',\n",
       " 'outsid',\n",
       " 'over',\n",
       " 'pack',\n",
       " 'pair',\n",
       " 'palmer',\n",
       " 'pang',\n",
       " 'park',\n",
       " 'parliament',\n",
       " 'parliament.+khalid',\n",
       " 'past',\n",
       " 'pattern',\n",
       " 'pedestrian',\n",
       " 'pei',\n",
       " 'penalti',\n",
       " 'peng',\n",
       " 'peopl',\n",
       " 'percent',\n",
       " 'phil',\n",
       " 'place',\n",
       " 'play',\n",
       " 'plenti',\n",
       " 'point',\n",
       " 'points.+elsewher',\n",
       " 'polic',\n",
       " 'policeman',\n",
       " 'polici',\n",
       " 'polit',\n",
       " 'post',\n",
       " 'potro',\n",
       " 'power',\n",
       " 'premier',\n",
       " 'prepar',\n",
       " 'presid',\n",
       " 'previou',\n",
       " 'princ',\n",
       " 'ranieri.+ibrahimov',\n",
       " 'rate',\n",
       " 'record',\n",
       " 'remain',\n",
       " 'report',\n",
       " 'result',\n",
       " 'resurg',\n",
       " 'retain',\n",
       " 'retir',\n",
       " 'return',\n",
       " 'rhode',\n",
       " 'ring',\n",
       " 'ringgit',\n",
       " 'rio',\n",
       " 'rise',\n",
       " 'roger',\n",
       " 'ron-peck',\n",
       " 'round',\n",
       " 'round.+in-form',\n",
       " 'royal',\n",
       " 'run',\n",
       " 'said',\n",
       " 'said.+at',\n",
       " 'said.+h',\n",
       " 'said.+th',\n",
       " 'same',\n",
       " 'save',\n",
       " 'scene',\n",
       " 'school',\n",
       " 'season',\n",
       " 'second',\n",
       " 'secur',\n",
       " 'sens',\n",
       " 'sensit',\n",
       " 'sent',\n",
       " 'serv',\n",
       " 'servic',\n",
       " 'set',\n",
       " 'shakespear',\n",
       " 'sharpli',\n",
       " 'shem-tan',\n",
       " 'shortli',\n",
       " 'shot',\n",
       " 'side',\n",
       " 'silver',\n",
       " 'sinc',\n",
       " 'sixth',\n",
       " 'slow',\n",
       " 'solgyu-cha',\n",
       " 'someth',\n",
       " 'soon',\n",
       " 'soon-goh',\n",
       " 'south',\n",
       " 'spoke',\n",
       " 'spot-kick',\n",
       " 'squar',\n",
       " 'stab',\n",
       " 'step',\n",
       " 'stori',\n",
       " 'strengthen',\n",
       " 'stronger',\n",
       " 'subaktiar-gloria',\n",
       " 'success',\n",
       " 'succumb',\n",
       " 'summit',\n",
       " 'sunderland',\n",
       " 'support',\n",
       " 'surg',\n",
       " 'survivor',\n",
       " 'suspens',\n",
       " 'take',\n",
       " 'tan',\n",
       " 'technic',\n",
       " 'terror',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'they',\n",
       " 'thi',\n",
       " 'third',\n",
       " 'those',\n",
       " 'three',\n",
       " 'thunder',\n",
       " 'to',\n",
       " 'told',\n",
       " 'took',\n",
       " 'tourist',\n",
       " 'trade',\n",
       " 'trafford',\n",
       " 'trail',\n",
       " 'train',\n",
       " 'trump',\n",
       " 'tuesday',\n",
       " 'tuesday.+a',\n",
       " 'two',\n",
       " 'two-year',\n",
       " 'u.s.',\n",
       " 'unbeaten',\n",
       " 'under',\n",
       " 'underperform',\n",
       " 'unit',\n",
       " 'unwelcom',\n",
       " 'us',\n",
       " 'utd',\n",
       " 'v',\n",
       " 'victims.+princ',\n",
       " 'wa',\n",
       " 'walk',\n",
       " 'walkov',\n",
       " 'way',\n",
       " 'weak',\n",
       " 'wednesday',\n",
       " 'wednesday.+th',\n",
       " 'wee',\n",
       " 'week',\n",
       " 'wei',\n",
       " 'weigh',\n",
       " 'went',\n",
       " 'were',\n",
       " 'westminst',\n",
       " 'when',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'widjaja',\n",
       " 'wife',\n",
       " 'william',\n",
       " 'win',\n",
       " 'window',\n",
       " 'wire',\n",
       " 'with',\n",
       " 'won',\n",
       " 'world',\n",
       " 'xi',\n",
       " 'year',\n",
       " 'yen',\n",
       " 'ying',\n",
       " 'yoo',\n",
       " 'you']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
